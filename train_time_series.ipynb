{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import parallel_plume_sim as pps\n",
    "import multiprocessing\n",
    "from scipy.interpolate import splprep, splev\n",
    "\n",
    "\n",
    "\n",
    "##animating\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as py\n",
    "\n",
    "## training\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, device):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device  # Add this line\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)  # 1 output (odor)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 3:  # If a batch of sequences is passed in\n",
    "            h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n",
    "            c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device)\n",
    "        elif x.dim() == 2:  # If a single sequence is passed in\n",
    "            h0 = torch.zeros(self.num_layers, 1, self.hidden_size).to(self.device)\n",
    "            c0 = torch.zeros(self.num_layers, 1, self.hidden_size).to(self.device)\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected input dimension: %d\" % x.dim())\n",
    "        out, _ = self.lstm(x.unsqueeze(0) if x.dim() == 2 else x, (h0, c0))\n",
    "        out = self.fc(out.squeeze(0) if x.dim() == 2 else out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "    def reset_hidden_state(self, batch_size):\n",
    "        self.hidden = (torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device),\n",
    "                       torch.zeros(self.num_layers, batch_size, self.hidden_size).to(self.device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    return (((data - min_val) / (max_val - min_val)) * 10)\n",
    "\n",
    "def load_and_preprocess_file(file_path, features, target):\n",
    "    # Load the data\n",
    "    df = pd.read_hdf(file_path)\n",
    "    df['scaled_odor']=scale_data(df.odor)\n",
    "    # Scale the features\n",
    "    scaler = MinMaxScaler()\n",
    "    df[features] = scaler.fit_transform(df[features])\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    feature_tensors = torch.Tensor(df[features].values)\n",
    "    target_tensors = torch.Tensor(df[target].values)\n",
    "\n",
    "    # Reshape to (seq_length, n_features)\n",
    "    feature_tensors = feature_tensors.view(-1, len(features))\n",
    "\n",
    "    return feature_tensors, target_tensors\n",
    "\n",
    "def create_sequences(feature_tensors, target_tensors, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(feature_tensors) - seq_length):\n",
    "        sequences.append(feature_tensors[i:i+seq_length])\n",
    "        targets.append(target_tensors[i+seq_length])\n",
    "    return torch.stack(sequences), torch.stack(targets)\n",
    "\n",
    "\n",
    "def train_on_single_file(model, optimizer, criterion, sequences, targets, num_epochs, batch_size):\n",
    "    model.train()\n",
    "    num_batches = len(sequences) // batch_size  # Determine the number of batches\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx in range(num_batches):  # Iterate over each batch\n",
    "            # Get the current batch of sequences and targets\n",
    "            batch_sequences = sequences[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "            batch_targets = targets[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "\n",
    "            # Reset the hidden state for each new batch\n",
    "            model.reset_hidden_state(batch_size)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_sequences.view(-1, seq_length, input_size))\n",
    "            # loss = criterion(outputs[:, -1, :], batch_targets.view(-1, 1))  # Compare only the last prediction with the target\n",
    "            loss = criterion(outputs[:, -1], batch_targets.view(-1, 1))  # Compare only the last prediction with the target\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "## faster method but needs more gpu\n",
    "# def train_on_single_file(model, optimizer, criterion, sequences, targets, num_epochs):\n",
    "#     model.train()\n",
    "#     batch_size = sequences.size(0)\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.reset_hidden_state(batch_size)\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(sequences.view(-1, seq_length, input_size))\n",
    "#         loss = criterion(outputs, targets.view(-1, 1))  # Compare the output directly with the target\n",
    "\n",
    "#         # Backward pass and optimization\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         if (epoch + 1) % 10 == 0:\n",
    "#             print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['windx', 'windy', 'x', 'y']\n",
    "target = ['scaled_odor']\n",
    "seq_length = 5  # Choose a suitable sequence length\n",
    "num_epochs = 10  # Choose a suitable number of epochs\n",
    "\n",
    "\n",
    "# Initialize LSTM model\n",
    "input_size = 4  # Number of features\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "model = LSTM(input_size, hidden_size, num_layers, device)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)  # Define your optimizer\n",
    "criterion = nn.MSELoss()  # Define your loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify the directory you're working from\n",
    "# folder_path = '/home/flybot/DataAnalysis/data/generated_data_plume_sim/test_2/'\n",
    "\n",
    "# # Get a list of all the .h5 files in the directory\n",
    "# files = [f for f in os.listdir(folder_path) if f.endswith('.h5')]\n",
    "\n",
    "# # Initialize an empty dataframe\n",
    "# all_data = pd.DataFrame()\n",
    "\n",
    "# # Loop through the files and read each one into a dataframe\n",
    "# for file in files:\n",
    "#     file_path = os.path.join(folder_path, file)\n",
    "#     df = pd.read_hdf(file_path)\n",
    "#     all_data = pd.concat([all_data, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flybot/DataAnalysis/pyresearch/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.01808532327413559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flybot/DataAnalysis/pyresearch/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.0050918953493237495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flybot/DataAnalysis/pyresearch/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.05834674462676048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flybot/DataAnalysis/pyresearch/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.0062976861372590065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flybot/DataAnalysis/pyresearch/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.008961953222751617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flybot/DataAnalysis/pyresearch/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 1.23643159866333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flybot/DataAnalysis/pyresearch/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.05752386897802353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flybot/DataAnalysis/pyresearch/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.00040167602128349245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flybot/DataAnalysis/pyresearch/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.27129966020584106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flybot/DataAnalysis/pyresearch/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.0012557079317048192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flybot/DataAnalysis/pyresearch/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.004938620608299971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flybot/DataAnalysis/pyresearch/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.2635224461555481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flybot/DataAnalysis/pyresearch/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# Iterate over files\n",
    "filepath=\"/home/flybot/DataAnalysis/data/generated_data_plume_sim/train/\"\n",
    "for file in os.listdir(filepath):  # Replace with the actual path\n",
    "    file_path = os.path.join(filepath, file)\n",
    "    feature_tensors, target_tensors = load_and_preprocess_file(file_path, features, target)\n",
    "    sequences, targets = create_sequences(feature_tensors, target_tensors, seq_length)\n",
    "    sequences = sequences.to(device)\n",
    "    targets = targets.to(device)\n",
    "    # train_on_single_file(model, optimizer, criterion, sequences, targets, num_epochs)\n",
    "    train_on_single_file(model, optimizer, criterion, sequences, targets, num_epochs, batch_size=32)  # Choose a suitable batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyresearch",
   "language": "python",
   "name": "pyresearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
